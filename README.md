# F-T_methods




##  タスク
```
目的： LLMが未学習の語彙を用いたデータテンプレート（JSON-LD）の「読み書き」を追加学習させる（Fine-tuning）。
調査検討して欲しいこと： 現在各所で検証されている「LLMの再学習手法」を調べて、上記目的に利用できそうな手法の候補を抽出。その後、幾つかの手法について試行／検証を行い、目的に対する適用可能性を探る。
```


## Methods

### PEFT

 
 
1. LoRA型

    パラメータに対してより低ランクの行列を計算し、その後高次元に復元することでパラメータの変更を行う手法

    ・メリット

    かなり短時間で学習を終えることができる

    様々なサンプルコードがあるので下記お安い

    ・デメリット

    学習データが増える壊滅的忘却が起きることがあ

    サンプルコード

    https://qiita.com/taka_yayoi/items/7f50d3ebbe4bebd6877c






2. Adapter型　
 　

    LLMに対してAdapterと呼ばれるサブモジュールを適用してパラメータ調節を行う手法


    ・メリット

    柔軟にAdapterの挿入、削除ができる

    Transformerの機能に影響を与えない

    ・デメリット

    推論にやや時間がかかる


    参考文献
    https://arxiv.org/pdf/1902.00751.pdf

    Hugging Faceの参考コード
    https://huggingface.co/docs/transformers/main/peft


    ・所感


    少し調べてみたところ、実行例が少なくコードのサンプルが少ないので少し苦戦しそう


### GPT を用いた方法

### GPT Builder

OpenAIから発表された、ChatGPTをカスタムできる機能

・メリット

簡単にfine-tuningを行うことができる

共有や公開が簡単にできる　　



・デメリット  
安全性にやや難あり(URLを持っている人のみに公開もできる)


・所感

コーディングなしで簡単にできる点が非常に魅力的  
また、Openaiのでオンストレーションでも５分以内にGPTsが完成していたので、上記の例に比べてかなり処理が早い

内部処理にはRAGを用いている  
色々触ってみたところ、かなりの精度でfine-tuningができてると実感　　
pdf読み込みなど、多数のファイル形式に対してそのままアップロードができる点が非常に使いやすい

### GPT3.5-turbo

GPTのAPIを利用してfine-tningを行う手法  

・メリット  
データを用意するだけで、他に難しいコードなどはいらない

・デメリット  
少し時間がかかる(リクエストしてから3時間ほど)

一つのAPIキーにつき３つまでしかモデルを保存できない

・参考コード

https://developers.play.jp/entry/2023/10/20/173222#6-Fine-tuningの進捗状況を確認する
### まとめ

今回は様々な手法を調べてみたが、私としてはGPTbuilderが簡単かつ適していると感じた    
GPTsの推奨さえれるタスクとして今回のような未学習データの学習が上げれれていたことと、かなり簡単にできるところが魅力的であった

またPEFTの中ではLoRAのほうが適しているように感じた  




